{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "import datetime\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "\n",
    "from gpflow.ci_utils import ci_niter, ci_range\n",
    "from gpflow.config import default_float\n",
    "from gpflow.utilities import print_summary\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tensorboard work inside notebook\n",
    "output_logdir = \"/tmp/tensorboard\"\n",
    "\n",
    "!rm -rf \"{output_logdir}\"\n",
    "!mkdir \"{output_logdir}\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def enumerated_logdir(_logdir_id: int = [0]):\n",
    "    logdir = Path(output_logdir, str(_logdir_id[0]))\n",
    "    _logdir_id[0] += 1\n",
    "    return str(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup random seeds and default float for gpflow tensors\n",
    "gpflow.config.set_default_float(np.float64)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "X_org = pd.DataFrame(diabetes['data'], columns = diabetes['feature_names'])\n",
    "y_org = pd.DataFrame(diabetes['target'], columns = ['y'])\n",
    "data = X_org\n",
    "data = data * np.shape(data)[0]\n",
    "data['y'] = np.log(y_org)\n",
    "data['sex'][data['sex']>0] = 1\n",
    "data['sex'][data['sex']<0] = 0\n",
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 5\n",
    "adam_learning_rate = 0.01\n",
    "iterations = ci_niter(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train)[:,:5]\n",
    "y = np.expand_dims(np.array(train['y']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = gpflow.kernels.SquaredExponential()\n",
    "vgp = gpflow.models.VGP(data=(X, y), likelihood=gpflow.likelihoods.StudentT(), kernel=k, mean_function=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Adam from optimizing the variational parameters\n",
    "vgp.q_mu.trainable = False\n",
    "vgp.q_sqrt.trainable = False\n",
    "\n",
    "variational_params = [(vgp.q_mu, vgp.q_sqrt)]\n",
    "\n",
    "adam_opt_for_vgp = tf.optimizers.Adam(adam_learning_rate)\n",
    "natgrad_opt = gpflow.optimizers.NaturalGradient(gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGP with NaturalGradient and Adam: iteration 1 likelihood -1845.0127\n",
      "VGP with NaturalGradient and Adam: iteration 21 likelihood -1641.4544\n",
      "VGP with NaturalGradient and Adam: iteration 41 likelihood -1546.0537\n",
      "VGP with NaturalGradient and Adam: iteration 61 likelihood -1469.8451\n",
      "VGP with NaturalGradient and Adam: iteration 81 likelihood -1408.5408\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "for i in range(iterations):\n",
    "    adam_opt_for_vgp.minimize(\n",
    "        lambda: - vgp.log_marginal_likelihood(),\n",
    "        var_list=vgp.trainable_variables)\n",
    "    natgrad_opt.minimize(\n",
    "        lambda: - vgp.log_marginal_likelihood(),\n",
    "        var_list = variational_params)\n",
    "    likelihood = vgp.log_likelihood()\n",
    "    if i%20==0:\n",
    "        tf.print(f'VGP with NaturalGradient and Adam: iteration {i + 1} likelihood {likelihood:.04f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate from GP\n",
    "param = [vgp.trainable_variables[0].numpy(),vgp.trainable_variables[1].numpy()]\n",
    "\n",
    "def cov_kernel(x1,x2,variance=1.0,lengthscale=1.0): \n",
    "    \"\"\"\n",
    "    Squared-Exponential covariance kernel\n",
    "    \"\"\" \n",
    "    k12 = variance*np.exp(-.5*np.sum((x1 - x2)**2)/lengthscale**2)\n",
    "    return k12\n",
    "\n",
    "def make_K(x,variance=1.0,lengthscale=1.0):\n",
    "    \"\"\"\n",
    "    Make covariance matrix from covariance kernel\n",
    "    \"\"\"\n",
    "    # for a data array of length x, make a covariance matrix x*x:\n",
    "    K = np.zeros((np.shape(x)[0],np.shape(x)[0]))\n",
    " \n",
    "    for i in range(0,len(x)):\n",
    "        for j in range(0,len(x)):\n",
    "            # calculate value of K for each separation:\n",
    "            K[i,j] = cov_kernel(x[i,:],x[j,:],variance,lengthscale)\n",
    "    return K\n",
    "\n",
    "np.random.seed(0)\n",
    "# draw samples from a co-variate Gaussian\n",
    "K = make_K(X,vgp.kernel.variance.numpy(),vgp.kernel.lengthscale.numpy())\n",
    "f_sim =  np.random.multivariate_normal(np.zeros(np.shape(X)[0]),K)\n",
    "\n",
    "# draw noise\n",
    "noise_sim = np.random.standard_t(param[0],np.shape(X)[0])\n",
    "y_sim = np.expand_dims(f_sim + noise_sim, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGP with NaturalGradient and Adam: iteration 1 likelihood -835.4203\n",
      "VGP with NaturalGradient and Adam: iteration 21 likelihood -822.2406\n",
      "VGP with NaturalGradient and Adam: iteration 41 likelihood -822.2406\n",
      "VGP with NaturalGradient and Adam: iteration 61 likelihood -822.2406\n",
      "VGP with NaturalGradient and Adam: iteration 81 likelihood -822.2406\n"
     ]
    }
   ],
   "source": [
    "# perform VGP on simulated data\n",
    "k2 = gpflow.kernels.SquaredExponential(vgp.kernel.variance.numpy(), vgp.kernel.lengthscale.numpy())\n",
    "vgp2 = gpflow.models.VGP(data=(X, y_sim), likelihood=gpflow.likelihoods.StudentT(), kernel=k2, mean_function=None) \n",
    "\n",
    "variational_params2 = [(vgp2.q_mu, vgp2.q_sqrt)]\n",
    "\n",
    "natgrad_opt = gpflow.optimizers.NaturalGradient(gamma=1.0)\n",
    "\n",
    "for i in range(iterations):\n",
    "    natgrad_opt.minimize(\n",
    "        lambda: - vgp2.log_marginal_likelihood(),\n",
    "        var_list = variational_params2)\n",
    "    likelihood = vgp2.log_likelihood()\n",
    "    if i%20==0:\n",
    "        tf.print(f'VGP with NaturalGradient and Adam: iteration {i + 1} likelihood {likelihood:.04f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_post = np.squeeze(vgp2.predict_f_samples(predict_at=X).numpy(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9b400f053d2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gp_dict'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgp_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "gp_dict = {'f_prior': f_sim, 'f_post': f_post}\n",
    "\n",
    "with open('gp_dict','wb') as handle:\n",
    "    pickle.dump(gp_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
